{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e5e6be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T16:17:56.145513Z",
     "start_time": "2021-11-26T16:17:54.638294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.chdir ('/home/wenyu/pycharm_projs/Categorical_encoding/')\n",
    "\n",
    "from initDesignDomain import initBO\n",
    "from sktools import QuantileEncoder\n",
    "import syntheticFunctions as test_func\n",
    "# -------------------START target packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# -------------------END target packages\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -------------------START Bortorch packages\n",
    "import torch\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.acquisition.analytic import ExpectedImprovement\n",
    "from botorch.acquisition.analytic import PosteriorMean\n",
    "from botorch.acquisition.analytic import ProbabilityOfImprovement\n",
    "from botorch.acquisition.analytic import UpperConfidenceBound\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models import SingleTaskGP\n",
    "from sklearn import preprocessing\n",
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "print('Libraries imported')\n",
    "\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6691bf3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T16:17:56.158154Z",
     "start_time": "2021-11-26T16:17:56.155716Z"
    }
   },
   "outputs": [],
   "source": [
    "def del_tensor_element(tensor, index):\n",
    "    t1 = tensor[0:index]\n",
    "    t2 = tensor[index + 1:]\n",
    "    return torch.cat((t1, t2), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1be69884",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T16:17:56.170544Z",
     "start_time": "2021-11-26T16:17:56.166488Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = 'OH'\n",
    "f = test_func.svm_mse\n",
    "obj_func = 'svm'\n",
    "C = [2]\n",
    "design_seed = 10000\n",
    "bounds = [\n",
    "    {'name': 'kernel', 'type': 'categorical', 'domain': tuple(range(3))},\n",
    "    {'name': 'C', 'type': 'continuous', 'domain': (1, 50)},  # C\n",
    "    {'name': 'epsilon', 'type': 'continuous', 'domain': (0, 1)}]  # epsilon\n",
    "max_trials = 20\n",
    "budget = 200\n",
    "init_N = 24\n",
    "df_list = []\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "init_data_path = 'experiment_data/benchmark/init_data/svm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1f86132",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-26T16:18:06.939598Z",
     "start_time": "2021-11-26T16:17:56.181121Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trial:  0\n",
      "self.saving_path: experiment_data/benchmark/init_data/svm/\n",
      "Using existing init data for seed 10000\n",
      "self.saving_path: experiment_data/benchmark/init_data/svm/\n",
      "init_fname:  True\n",
      "os.path <module 'posixpath' from '/home/wenyu/.conda/envs/torch/lib/python3.8/posixpath.py'>\n",
      "Using existing init data for seed 0\n",
      "iteration:  0\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  1\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  2\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  3\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  4\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  5\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  6\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  7\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  8\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  9\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  10\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  11\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  12\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  13\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  14\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  15\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  16\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  17\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  18\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "iteration:  19\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "for trial in range(max_trials):\n",
    "    print(\"num_trial: \", trial)\n",
    "    design_obj = initBO(objfn=f, initN=design_seed, bounds=bounds, C=C, saving_path=init_data_path)\n",
    "    design_data = design_obj.sampling_at_least_once_z(seed=design_seed)\n",
    "    OHE = OneHotEncoder(cols=list(range(len(C)))).fit(design_data)\n",
    "\n",
    "    init_obj = initBO(f, init_N, bounds, C, saving_path=init_data_path)\n",
    "    data, y = init_obj.initialise(seed=trial)\n",
    "    y_s = scaler.fit_transform(y)\n",
    "    z = OHE.transform(data)\n",
    "    maxindex_list = []\n",
    "    cand_y_list = []\n",
    "    max_y_list = []\n",
    "    for iteration in range(budget):\n",
    "        print(\"iteration: \", iteration)\n",
    "        gp = SingleTaskGP(torch.from_numpy(np.array(z)), y).to(dtype=torch.double)\n",
    "        mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "        fit_gpytorch_model(mll)\n",
    "        design_z = torch.from_numpy(OHE.transform(design_data).values)\n",
    "        beta = 20 * 0.985 ** iteration\n",
    "        # print(\"beta: \", beta)\n",
    "        UCB = UpperConfidenceBound(model=gp, beta=beta)\n",
    "        try:\n",
    "            acq_value = UCB(design_z.unsqueeze(-2))\n",
    "        except:\n",
    "            print(f\"{trial}_error_{iteration}_iteration\")\n",
    "            #             with open(f\"./experiment_data/func2C_cholesky_error/{obj_func}_double__q_{quantile_flag}_trial_{trial}_iter_{iteration}\", \"wb\") as file:\n",
    "            #                 pickle.dump(z, file)\n",
    "            break\n",
    "\n",
    "        max_index = torch.argmax(acq_value, dim=-1).tolist()\n",
    "        maxindex_list.append(max_index)\n",
    "        # candidate\n",
    "        candidate_h_x = design_data[max_index]\n",
    "#         candidate_y = design_y[max_index].unsqueeze(0)\n",
    "        candidate_y = torch.tensor(f([candidate_h_x[0]], candidate_h_x[1:])).unsqueeze(0)\n",
    "        data = np.vstack((data, candidate_h_x))\n",
    "        y = torch.vstack((y, candidate_y))\n",
    "        y_s = scaler.transform(y)\n",
    "        z = OHE.transform(data)\n",
    "        cand_y_list.append(candidate_y.item())\n",
    "        max_y_list.append(y.max().item())\n",
    "        design_data = np.delete(design_data, max_index, axis=0)\n",
    "#         design_y = del_tensor_element(design_y, max_index)\n",
    "\n",
    "    final_max = max(max_y_list)\n",
    "    df_list.append([trial, final_max, cand_y_list, max_y_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31d14089",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T13:41:46.710825Z",
     "start_time": "2021-11-17T13:41:46.706743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------duration= 3976.9409408459906\n"
     ]
    }
   ],
   "source": [
    "end = time.perf_counter()\n",
    "duration = end - start\n",
    "# df = pd.DataFrame(df_list, columns=['num_trial', 'final_max', 'iter_cand_y_list', 'iter_current_max'])\n",
    "saving_path = f'./experiment_data/benchmark/result/svm/'\n",
    "file_name = f\"{saving_path}{obj_func}_trials_{max_trials}_budget_{budget}_onehot_ucbdecay_duration{round(duration)}\"\n",
    "output = open(file_name, 'wb')\n",
    "pickle.dump(df_list, output)\n",
    "output.close()\n",
    "print(\"-----------duration=\", duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
