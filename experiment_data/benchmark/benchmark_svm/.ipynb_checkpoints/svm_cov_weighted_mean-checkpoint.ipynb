{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a57069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T15:10:58.571230Z",
     "start_time": "2021-11-27T15:10:57.293557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.chdir ('/home/wenyu/pycharm_projs/Categorical_encoding/')\n",
    "\n",
    "from initDesignDomain import initBO\n",
    "from sktools import QuantileEncoder, SummaryEncoder\n",
    "import syntheticFunctions as test_func\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# -------------------START Bortorch packages \n",
    "import torch\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from pandas import DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.kernels import RBFKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.acquisition.analytic import ExpectedImprovement\n",
    "from botorch.acquisition.analytic import PosteriorMean\n",
    "from botorch.acquisition.analytic import ProbabilityOfImprovement\n",
    "from botorch.acquisition.analytic import UpperConfidenceBound\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models import SingleTaskGP\n",
    "from sklearn import preprocessing\n",
    "# from category_encoders import TargetEncoder as TE\n",
    "from category_encoders import TargetEncoder \n",
    "\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "print('Libraries imported')\n",
    "# -------------------END Bortorch packages \n",
    "\n",
    "# -------------------START\n",
    "import pickle\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141409e2",
   "metadata": {},
   "source": [
    "# BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a68375e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T15:10:58.575644Z",
     "start_time": "2021-11-27T15:10:58.572646Z"
    }
   },
   "outputs": [],
   "source": [
    "def del_tensor_element(tensor, index):\n",
    "    t1 = tensor[0:index]\n",
    "    t2 = tensor[index + 1:]\n",
    "    return torch.cat((t1, t2), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "741ea62a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T15:10:58.580425Z",
     "start_time": "2021-11-27T15:10:58.577184Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = 'cov_mean'\n",
    "obj_func = 'svm'\n",
    "design_seed = 10000\n",
    "f = test_func.svm_mse\n",
    "C = [3]\n",
    "bounds = [\n",
    "    {'name': 'kernel', 'type': 'categorical', 'domain': tuple(range(3))},\n",
    "    {'name': 'C', 'type': 'continuous', 'domain': (1, 50)},  # C\n",
    "    {'name': 'epsilon', 'type': 'continuous', 'domain': (0, 1)}]  # epsilon\n",
    "\n",
    "max_trials = 1\n",
    "budget = 20\n",
    "init_N = 24\n",
    "df_list = []\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "init_data_path = 'experiment_data/benchmark/init_data/svm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "910810d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T15:10:59.729717Z",
     "start_time": "2021-11-27T15:10:58.585829Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------num_trial:  0\n",
      "self.saving_path: experiment_data/benchmark/init_data/svm/\n",
      "Using existing init data for seed 10000\n",
      "self.saving_path: experiment_data/benchmark/init_data/svm/\n",
      "init_fname:  True\n",
      "os.path <module 'posixpath' from '/home/wenyu/.conda/envs/torch/lib/python3.8/posixpath.py'>\n",
      "Using existing init data for seed 0\n",
      "iteration:  0\n",
      "ard_num_dims=None .!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "weight  0 [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan]\n",
      "iteration:  1\n"
     ]
    },
    {
     "ename": "InputDataError",
     "evalue": "Input data contains NaN values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInputDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_125188/2086279370.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iteration: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdesign_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesign_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mgp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleTaskGP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mmll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExactMarginalLogLikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mfit_gpytorch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch/lib/python3.8/site-packages/botorch/models/gp_regression.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, train_X, train_Y, likelihood, covar_module, outcome_transform)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutcome_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_tensor_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mvalidate_input_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_tensor_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch/lib/python3.8/site-packages/botorch/models/utils.py\u001b[0m in \u001b[0;36mvalidate_input_scaling\u001b[0;34m(train_X, train_Y, train_Yvar, raise_on_fail)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_input_scaling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0mcheck_no_nans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0mcheck_no_nans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrain_Yvar\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/torch/lib/python3.8/site-packages/botorch/models/utils.py\u001b[0m in \u001b[0;36mcheck_no_nans\u001b[0;34m(Z)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mInputDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input data contains NaN values.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInputDataError\u001b[0m: Input data contains NaN values."
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "for trial in range(max_trials):\n",
    "    print(\"----------num_trial: \", trial)\n",
    "    design_obj = initBO(objfn=f, initN=design_seed, bounds=bounds, C=C, saving_path=init_data_path)\n",
    "    design_data = design_obj.sampling_at_least_once_z(seed=design_seed)\n",
    "    \n",
    "    init_obj = initBO(f, init_N, bounds, C, saving_path=init_data_path)\n",
    "    data, y = init_obj.initialise(seed=trial)\n",
    "    y_s = scaler.fit_transform(y)\n",
    "\n",
    "    TE = TargetEncoder(cols=list(range(len(C)))).fit(data, y_s)\n",
    "    z = TE.transform(data)\n",
    "\n",
    "    maxindex_list = []\n",
    "    cand_y_list = []\n",
    "    max_y_list = []\n",
    "    for iteration in range(budget):\n",
    "        print(\"iteration: \", iteration)\n",
    "        design_z = torch.from_numpy(TE.transform(design_data).values)\n",
    "        gp = SingleTaskGP(torch.from_numpy(np.array(z)), y).to(dtype=torch.double)\n",
    "        mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "        fit_gpytorch_model(mll)\n",
    "        beta = 20 * 0.985 ** iteration\n",
    "        UCB = UpperConfidenceBound(model=gp, beta=beta)\n",
    "        try:\n",
    "            acq_value = UCB(design_z.unsqueeze(-2))\n",
    "        except:\n",
    "            print(f\"{trial}_error!!!!!!!!!!!!_{iteration}_iteration\")\n",
    "            break\n",
    "\n",
    "        max_index = torch.argmax(acq_value, dim=-1).tolist()\n",
    "        maxindex_list.append(max_index)\n",
    "        # candidate\n",
    "        candidate_h_x = design_data[max_index]\n",
    "        candidate_y = torch.tensor(f([candidate_h_x[0]], candidate_h_x[1:])).unsqueeze(0)\n",
    "        data = np.vstack((data, candidate_h_x))\n",
    "        y = torch.vstack((y, candidate_y))\n",
    "#         y_s = scaler.fit_transform(y)\n",
    "        y_s = scaler.transform(y)\n",
    "        cand_y_list.append(candidate_y.item())\n",
    "        max_y_list.append(y.max().item())\n",
    "        design_data = np.delete(design_data, max_index, axis=0)\n",
    "#         design_y = del_tensor_element(design_y, max_index)\n",
    "\n",
    "        z = TE.transform(data)\n",
    "        cov = gp.covar_module(torch.from_numpy(z.values)).numpy()\n",
    "        # cov = gp.covar_module(torch.from_numpy(data.value)).numpy()\n",
    "#         print(\"cov\", cov)\n",
    "        row, col = np.diag_indices_from(cov)\n",
    "        cov[row,col] = np.zeros([cov.shape[0]])\n",
    "        # Second order inverse distance weighting\n",
    "        d_power = cov.sum(axis=1)**(-2)\n",
    "        d_sum = d_power.sum()\n",
    "        weight = d_power/d_sum\n",
    "        print(f\"weight  {iteration}\", weight)\n",
    "        y_s = (y_s.reshape(-1) * weight).reshape(-1, 1)\n",
    "\n",
    "        TE = TargetEncoder(cols=list(range(len(C)))).fit(data, y_s)\n",
    "        z = TE.transform(data)\n",
    "#         print(f\"z{iteration}\", z)\n",
    "#         print(\"mapping\",TE.mapping)\n",
    "        \n",
    "        \n",
    "    final_max = max(max_y_list)\n",
    "    df_list.append([trial, final_max, cand_y_list, max_y_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdefd4cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T15:10:59.731633Z",
     "start_time": "2021-11-27T15:10:59.731619Z"
    }
   },
   "outputs": [],
   "source": [
    "# end = time.perf_counter()\n",
    "# duration = end - start\n",
    "\n",
    "# df = pd.DataFrame(df_list, columns=['num_trial', 'final_max', 'iter_cand_y_list', 'iter_current_max'])\n",
    "# saving_path = f'./experiment_data/benchmark/result/Ackley5C/'\n",
    "# file_name = f\"{saving_path}{obj_func}_trials_{max_trials}_budget_{budget}_{encoder}_ucbdecay_duration{round(duration)}\"\n",
    "# output = open(file_name, 'wb')\n",
    "# pickle.dump(df_list, output)\n",
    "# output.close()\n",
    "# print(\"-----------duration=\", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e4d0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-27T15:10:59.732771Z",
     "start_time": "2021-11-27T15:10:59.732759Z"
    }
   },
   "outputs": [],
   "source": [
    "max_y_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 478.183334,
   "position": {
    "height": "40px",
    "left": "1253.67px",
    "right": "20px",
    "top": "120px",
    "width": "326.333px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
